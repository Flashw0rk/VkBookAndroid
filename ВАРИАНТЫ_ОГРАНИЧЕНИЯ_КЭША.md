# Варианты ограничения размера кэша Excel до 80 МБ

## Текущая ситуация
- Кэш хранит **ВСЕ** строки из Excel файла
- Формат: JSON файлы без сжатия
- Максимальный размер сейчас: 500 МБ (в FileSizeValidator)
- Требуется: ограничить до 80 МБ

---

## Вариант 1: Ограничение количества кэшируемых строк ⭐ РЕКОМЕНДУЕТСЯ

### Суть
Кэшировать только первые N строк каждого файла (например, первые 50,000 строк).

### Преимущества
- ✅ Простота реализации
- ✅ Предсказуемый размер кэша
- ✅ Быстрая работа (не нужно сжимать/распаковывать)
- ✅ Поиск работает быстро для первых строк

### Недостатки
- ❌ Поиск по строкам после N будет медленнее (чтение из исходного Excel)
- ❌ Нужно определить оптимальное N для каждого типа файла

### Реализация
```kotlin
// В ExcelCacheManager.kt
private const val MAX_CACHED_ROWS_PER_FILE = 50_000 // ~20 МБ на файл
private const val MAX_TOTAL_CACHE_SIZE = 80 * 1024 * 1024 // 80 МБ

// В buildCache() добавить проверку:
while (start <= totalRows && cachedRowsCount < MAX_CACHED_ROWS_PER_FILE) {
    // ... существующий код ...
    cachedRowsCount += taken
}
```

### Оценка размера
- 50,000 строк × 400 байт = ~20 МБ на файл
- 3-4 файла × 20 МБ = 60-80 МБ ✅

---

## Вариант 2: Сжатие JSON файлов (GZIP)

### Суть
Сохранять JSON файлы в сжатом виде (GZIP), что уменьшает размер в 3-5 раз.

### Преимущества
- ✅ Кэшируются ВСЕ строки
- ✅ Экономия места в 3-5 раз
- ✅ Стандартный формат (GZIP)

### Недостатки
- ❌ Нужно распаковывать при чтении (небольшая задержка)
- ❌ Сложнее отлаживать (файлы в бинарном виде)
- ❌ Дополнительная нагрузка на CPU при записи/чтении

### Реализация
```kotlin
// При записи:
val json = gson.toJson(rows)
val compressed = json.encodeToByteArray().gzip()
pageFile.writeBytes(compressed)

// При чтении:
val compressed = pageFile.readBytes()
val json = compressed.gunzip().decodeToString()
val rows = gson.fromJson(json, type)
```

### Оценка размера
- Без сжатия: 100,000 строк = ~40 МБ
- Со сжатием: 100,000 строк = ~8-12 МБ ✅
- 3-4 файла × 12 МБ = 36-48 МБ ✅

---

## Вариант 3: LRU кэш с автоматическим удалением старых файлов

### Суть
При превышении 80 МБ удалять самые старые/редко используемые кэши.

### Преимущества
- ✅ Автоматическое управление размером
- ✅ Сохраняются наиболее используемые данные
- ✅ Гибкость (можно кэшировать разные файлы)

### Недостатки
- ❌ Сложность реализации (нужно отслеживать использование)
- ❌ Может удалить нужный кэш
- ❌ Нужна система приоритетов

### Реализация
```kotlin
// В ExcelCacheManager.kt
private fun ensureCacheSizeLimit() {
    val rootDir = rootDir()
    val totalSize = calculateDirectorySize(rootDir)
    
    if (totalSize > MAX_TOTAL_CACHE_SIZE) {
        // Сортируем по времени последнего использования
        val datasets = rootDir.listFiles()?.sortedBy { 
            it.lastModified() 
        } ?: return
        
        var currentSize = totalSize
        for (dataset in datasets) {
            if (currentSize <= MAX_TOTAL_CACHE_SIZE * 0.8) break
            val size = calculateDirectorySize(dataset)
            dataset.deleteRecursively()
            currentSize -= size
        }
    }
}
```

---

## Вариант 4: Комбинированный подход ⭐ ЛУЧШИЙ

### Суть
Комбинация вариантов 1 и 2:
- Ограничение до 50,000 строк на файл
- Сжатие JSON файлов
- Автоматическая очистка при превышении лимита

### Преимущества
- ✅ Максимальная экономия места
- ✅ Быстрая работа (первые строки в памяти)
- ✅ Автоматическое управление размером
- ✅ Гарантированное соблюдение лимита 80 МБ

### Недостатки
- ❌ Более сложная реализация
- ❌ Нужно тестировать производительность

### Реализация
```kotlin
// Комбинация всех механизмов:
1. MAX_CACHED_ROWS_PER_FILE = 50_000
2. GZIP сжатие JSON
3. Проверка размера перед созданием кэша
4. Автоматическая очистка старых кэшей
```

### Оценка размера
- 50,000 строк × 400 байт = 20 МБ
- Со сжатием: 20 МБ / 3 = ~7 МБ на файл
- 3-4 файла × 7 МБ = 21-28 МБ ✅ (с большим запасом!)

---

## Вариант 5: Адаптивное ограничение строк

### Суть
Динамически определять количество строк в зависимости от размера файла и доступного места.

### Преимущества
- ✅ Оптимальное использование места
- ✅ Учитывает размер исходного файла
- ✅ Автоматическая адаптация

### Недостатки
- ❌ Сложность расчета
- ❌ Нужна статистика использования

### Реализация
```kotlin
private fun calculateMaxRowsForFile(fileSize: Long, availableSpace: Long): Int {
    // Оценка: 1 МБ исходного файла ≈ 2 МБ кэша
    val estimatedCacheSize = fileSize * 2
    val maxRows = if (estimatedCacheSize > availableSpace) {
        (availableSpace / 2 / 400).toInt() // 400 байт на строку
    } else {
        50_000 // По умолчанию
    }
    return maxRows.coerceIn(1000, 100_000) // Минимум 1000, максимум 100000
}
```

---

## Рекомендация

**Вариант 4 (Комбинированный)** - лучший выбор:
1. Ограничение до 50,000 строк на файл
2. GZIP сжатие JSON файлов
3. Автоматическая очистка при превышении 80 МБ

Это обеспечит:
- Размер кэша: ~20-30 МБ (с запасом до 80 МБ)
- Быструю работу поиска
- Автоматическое управление размером
- Гарантированное соблюдение лимита

---

## Сравнительная таблица

| Вариант | Размер кэша | Скорость поиска | Сложность | Рекомендация |
|---------|-------------|-----------------|-----------|--------------|
| 1. Ограничение строк | ~60-80 МБ | ⭐⭐⭐⭐⭐ | ⭐⭐ | ✅ Хорошо |
| 2. Сжатие GZIP | ~30-50 МБ | ⭐⭐⭐⭐ | ⭐⭐⭐ | ✅ Хорошо |
| 3. LRU удаление | ~80 МБ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⚠️ Средне |
| 4. Комбинированный | ~20-30 МБ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ✅ Лучший |
| 5. Адаптивный | ~40-60 МБ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⚠️ Сложно |

